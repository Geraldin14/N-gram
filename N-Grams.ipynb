{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81c19e4b",
   "metadata": {},
   "source": [
    "# TALLER N-GRAMS\n",
    "\n",
    "## fase 3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0541676",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, re, string, collections\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "975a086c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('internet_archive.txt','r',encoding= 'us-ascii') as file:\n",
    "    texto = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f07d88b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MARCH  All Stories New and Complete Publisher Editor IF is published bimonthly by Quinn Publishing Company Inc Kingston New York Volume  No  Copyright  by Quinn Publishing Company Inc Application for Entry as Second Class matter at Post Office Buffalo New York pending Subscription  for  issues in US and Possessions Canada  for  issues elsewhere  Aiiow four weeks for change of address All stories appearing in this magazine are fiction Any similarity to actual persons is coincidental c a fcopy Printed ia US A A chat with the editor  i   science fiction magazine called IF The title was selected after much thought because of its brevity and on the theory it is indicative of the field and will be easy to remember The tentative title that just morning and couldnt remember it until wed had a cup of coffee it was summarily discarded A great deal of thought and effort lias gone into the formation of this magazine We have had the aid of several very talented and generous people for which we are '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's do some preprocessing. We don't care about the XML notation, new lines \n",
    "# or punctuation marks other than periods. (We'll consider the end of the sentence\n",
    "# a \"word\") We also don't want to consider capitalization. \n",
    "\n",
    "# get rid of all the XML markup\n",
    "texto = re.sub('<.*>','',texto)\n",
    "\n",
    "# get rid of the \"ENDOFARTICLE.\" text\n",
    "texto = re.sub('ENDOFARTICLE.','',texto)\n",
    "\n",
    "# get rid of punctuation (except periods!)\n",
    "punctuationNoPeriod = \"[\" + re.sub(\"\\.\",\"\",string.punctuation) + \"]\"\n",
    "texto = re.sub(punctuationNoPeriod, \"\", texto)\n",
    "\n",
    "# make sure it looks ok\n",
    "texto[0:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8a9754",
   "metadata": {},
   "source": [
    "# BI-GRAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f1189ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first get individual words\n",
    "tokenized = texto.split()\n",
    "\n",
    "# and get a list of all the bi-grams\n",
    "esBigrams = ngrams(tokenized, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f0990a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('of', 'the'), 156483),\n",
       " (('in', 'the'), 94750),\n",
       " (('to', 'the'), 68557),\n",
       " (('on', 'the'), 54418),\n",
       " (('and', 'the'), 41703),\n",
       " (('at', 'the'), 40634),\n",
       " (('to', 'be'), 38960),\n",
       " (('from', 'the'), 34771),\n",
       " (('was', 'a'), 32611),\n",
       " (('in', 'a'), 31005)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the frequency of each bigram in our corpus\n",
    "esBigramFreq = collections.Counter(esBigrams)\n",
    "\n",
    "# what are the ten most popular ngrams in this English corpus?\n",
    "esBigramFreq.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a6930d",
   "metadata": {},
   "source": [
    "# TRI-GRAMS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d09f778c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first get individual words\n",
    "tokenized = texto.split()\n",
    "\n",
    "# and get a list of all the tri-grams\n",
    "esTrigrams = ngrams(tokenized, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7711420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('one', 'of', 'the'), 9131),\n",
       " (('out', 'of', 'the'), 8157),\n",
       " (('I', 'dont', 'know'), 5091),\n",
       " (('There', 'was', 'a'), 4827),\n",
       " (('It', 'was', 'a'), 4497),\n",
       " (('back', 'to', 'the'), 3869),\n",
       " (('a', 'lot', 'of'), 3616),\n",
       " (('to', 'be', 'a'), 3482),\n",
       " (('be', 'able', 'to'), 3443),\n",
       " (('the', 'rest', 'of'), 3364)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the frequency of each bigram in our corpus\n",
    "esTrigramFreq = collections.Counter(esTrigrams)\n",
    "\n",
    "# what are the ten most popular ngrams in this English corpus?\n",
    "esTrigramFreq.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e839e9",
   "metadata": {},
   "source": [
    "# TETRA-GRAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdcfaea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first get individual words\n",
    "tokenized = texto.split()\n",
    "\n",
    "# and get a list of all the tetra-grams\n",
    "esTetragrams = ngrams(tokenized, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83b3e63b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('the', 'edge', 'of', 'the'), 1615),\n",
       " (('the', 'rest', 'of', 'the'), 1554),\n",
       " (('the', 'end', 'of', 'the'), 1486),\n",
       " (('for', 'the', 'first', 'time'), 1364),\n",
       " (('the', 'center', 'of', 'the'), 1171),\n",
       " (('in', 'the', 'middle', 'of'), 1103),\n",
       " (('at', 'the', 'same', 'time'), 977),\n",
       " (('for', 'a', 'long', 'time'), 883),\n",
       " (('at', 'the', 'end', 'of'), 866),\n",
       " (('I', 'dont', 'know', 'what'), 846)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the frequency of each bigram in our corpus\n",
    "esTetragramFreq = collections.Counter(esTetragrams)\n",
    "\n",
    "# what are the ten most popular ngrams in this English corpus?\n",
    "esTetragramFreq.most_common(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
